import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from joblib import dump
from sklearn.metrics import classification_report

# Generate synthetic water quality data (1000 samples)
np.random.seed(42)

def generate_water_data(n_samples=1000):
    # Safe water parameters
    safe_ph = np.random.normal(7.0, 0.5, n_samples)
    safe_turbidity = np.abs(np.random.normal(1.0, 0.5, n_samples))
    safe_do = np.random.normal(8.0, 1.0, n_samples)
    safe_cond = np.random.normal(500, 100, n_samples)
    safe_temp = np.random.normal(25, 3, n_samples)
    safe_chlorine = np.abs(np.random.normal(0.5, 0.2, n_samples))
    safe_nitrate = np.abs(np.random.normal(5, 2, n_samples))
    
    # Contaminated water parameters
    contam_ph = np.concatenate([
        np.random.normal(4.5, 1.0, n_samples//2),
        np.random.normal(9.0, 1.0, n_samples//2)
    ])
    contam_turbidity = np.abs(np.random.normal(10.0, 5.0, n_samples))
    contam_do = np.abs(np.random.normal(3.0, 2.0, n_samples))
    contam_cond = np.abs(np.random.normal(1500, 500, n_samples))
    contam_temp = np.random.normal(30, 5, n_samples)
    contam_chlorine = np.abs(np.random.normal(0.1, 0.1, n_samples))
    contam_nitrate = np.abs(np.random.normal(15, 5, n_samples))
    
    # Combine data
    safe_data = np.column_stack([
        safe_ph, safe_turbidity, safe_do, safe_cond, 
        safe_temp, safe_chlorine, safe_nitrate
    ])
    contam_data = np.column_stack([
        contam_ph, contam_turbidity, contam_do, contam_cond,
        contam_temp, contam_chlorine, contam_nitrate
    ])
    
    X = np.vstack([safe_data, contam_data])
    y = np.array([0]*n_samples + [1]*n_samples)
    
    return pd.DataFrame(X, columns=[
        'ph', 'turbidity', 'do', 'cond', 'temp', 'chlorine', 'nitrate'
    ]), y

# Generate data
X, y = generate_water_data(1000)

# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train model
model = RandomForestClassifier(
    n_estimators=150,
    max_depth=10,
    min_samples_split=5,
    class_weight='balanced',
    random_state=42
)
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

# Feature importances
print("\nFeature Importances:")
for name, importance in zip(X.columns, model.feature_importances_):
    print(f"{name}: {importance:.2f}")

# Save model
dump(model, 'water_quality_model.joblib')
print("\nModel saved as 'water_quality_model.joblib'")